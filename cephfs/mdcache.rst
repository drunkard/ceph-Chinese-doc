=========================
 CephFS 分布式元数据缓存
=========================
.. CephFS Distributed Metadata Cache

在 Ceph 文件系统中， inode 的数据存储在 RADOS 中，客户端可以直接访问，
而 inode 元数据和目录信息则由 Ceph 元数据服务器（ MDS ）管理。
MDS 充当所有元数据相关活动的中介，
将产生的信息存储在与文件数据不同的 RADOS 存储池中。

CephFS 客户端可以请求 MDS 代表它提取或更改 inode 元数据，
但 MDS 也可以给每个 inode 授予客户端能力（又叫 caps ）
（参阅 :doc:`/cephfs/capabilities` ）。

能力授予客户端后，它能够缓存并可能操作\
与这个 inode 相关联的部分数据或元数据。
当其他客户端需要访问同一个信息时， MDS 会撤销该能力，
客户端最终会把这个能力、连同更新过的新版 inode 元数据
（如果客户端在持有该能力时对它进行了更改）一并返回。

客户端可以请求能力，通常也会获得这些能力，
但在遇到竞争访问或 MDS 存在内存压力时，
这些能力可能会\ **被撤销（ revoked ）**\ 。
当能力被撤销时，客户端有责任尽快归还能力。
未能及时归还的客户端可能会被列入\ **阻塞名单**\ ，
无法与集群通信。

由于缓存是分布式的，因此 MDS 必须非常小心地确保，
所有客户端所持有的能力都不会与其他客户端的能力、或自己的操作发生冲突。
这使得 cephfs 客户端可以信赖比其他文件系统（如 NFS ）更强的缓存一致性，
比如客户端可以放心地缓存数据和元数据，
而它们在服务器上已经被更改过了。


客户端元数据请求
----------------
.. Client Metadata Requests

当客户端需要查询/更改 inode 元数据或对目录做个操作时，
有两种选择。它可以直接向 MDS 发出请求，或者把要修改的信息注入缓存。
在 CephFS 中，只有当客户端拥有必要的 caps 时，才可以用后者。

客户端可以向 MDS 发送简单请求，以查询或请求更改某些元数据。
对这些请求的回复可能是授予这个客户端一组特定的 caps ，
让它操作 inode ，无需咨询 MDS 即可执行后续请求。

客户端还可以直接向 MDS 申请 caps ，要读取或写入文件数据时有必要这样。


MDS 集群里的分布式锁
--------------------
.. Distributed Locks in an MDS Cluster

当一个 MDS 想要读取或更改一个 inode 的信息时，
它必须收集对应的锁。 MDS 集群可能在指定的
inode 上有一系列不同类型的锁，
每个 MDS 可能都有互不关联的锁集。

如果有未完成的 caps 和这些锁有冲突，
那就必须先撤销这些 caps 让它们变得可获取。
等竞争的 caps 归还给 MDS 后，
它就可以获得锁并执行操作。

在由多个 MDS 提供服务的文件系统中，
元数据缓存也分布在集群中的多个 MDS 之间。
对于每一个 inode ，不管什么时候，集群中只有一个 MDS 是\ **权威的**\ 。
所有需要更改这个 inode 的请求都必须由权威 MDS 完成，
虽说非权威 MDS 可以接受请求，但它得转发给权威 MDS 。

非权威 MDS 还可以获取读出锁，
它能阻止授权 MDS 更改数据，直到锁被释放，
这样它们就可以向客户端提供 inode 信息。

一个 inode 的权威 MDS 也会随时间而变化。
MDS 们会时刻相互平衡、负责 inode 的缓存，
但这种行为可以改变，把某些子树\ **锁定（ pinning ）**\
到指定的单个 MDS 即可。
